{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom collections import Counter\nimport random\nimport json\nimport re\nfrom sklearn.manifold import TSNE\nfrom scipy import spatial\nimport matplotlib.pyplot as plt\nimport pickle\nimport torch.nn.functional as F\nimport random\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T19:59:27.357641Z","iopub.execute_input":"2023-05-03T19:59:27.358179Z","iopub.status.idle":"2023-05-03T19:59:27.370208Z","shell.execute_reply.started":"2023-05-03T19:59:27.358140Z","shell.execute_reply":"2023-05-03T19:59:27.368974Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7e5d62e4fc90>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Processing data and gold file","metadata":{}},{"cell_type":"code","source":"# preprocess data and gold file +  convert bi and trigrams to a underscore seperated word\n\nsubtask = \"2B.music\"\nphase = \"training\"\n\nf = open(f'/kaggle/input/inlp-project/{subtask}.{phase}.data.txt','r')\ndata = f.read()\nf.close()\nf = open(f'/kaggle/input/inlp-project/{subtask}.{phase}.gold.txt','r')\ngold = f.read()\nf.close()\nf = open(f'/kaggle/input/inlp-project/{subtask}.vocabulary.txt','r')\nVocab = f.read()\nf.close()\n\ndata = data.split('\\n')\ngold = gold.split('\\n')\nVocab = Vocab.split('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-05-03T19:59:28.896775Z","iopub.execute_input":"2023-05-03T19:59:28.897519Z","iopub.status.idle":"2023-05-03T19:59:28.917527Z","shell.execute_reply.started":"2023-05-03T19:59:28.897479Z","shell.execute_reply":"2023-05-03T19:59:28.916453Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"w2i = {}\ni2w = {}\nvocab = []\nind = 1\n\nw2i['UNK'] = 0\ni2w[0] = 'UNK'\nvocab.append('UNK')\n\n\nfor line in tqdm(Vocab):\n    line = line.lower()\n    line = line.split(' ') \n    joined_word = \"\"\n    for w in line:\n        joined_word += w +\"_\"\n    joined_word = joined_word[:-1]\n    \n    w2i[joined_word] = ind\n    i2w[ind] = joined_word\n    vocab.append(joined_word)\n    ind += 1\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2023-05-03T19:59:30.903878Z","iopub.execute_input":"2023-05-03T19:59:30.904826Z","iopub.status.idle":"2023-05-03T19:59:31.034251Z","shell.execute_reply.started":"2023-05-03T19:59:30.904774Z","shell.execute_reply":"2023-05-03T19:59:31.033091Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 69119/69119 [00:00<00:00, 606815.49it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"hyponyms = []\n\nfor line in data:\n    line = line.lower()\n    line = line.split(\"\\t\")\n    line = line[0]\n    line = line.split(\" \")\n    if len(line)>1:\n        joined_word = \"\"\n        for word in line:\n            joined_word += word + \"_\"\n        joined_word = joined_word[:-1]\n        if joined_word not in w2i.keys():\n            l = len(w2i.keys())\n            w2i[joined_word] = l\n            i2w[l] = joined_word\n            vocab.append(joined_word)\n        hyponyms.append(joined_word)\n    else:\n        hyponyms.append(line[0])\n        joined_word = line[0]\n        if joined_word not in w2i.keys():\n            l = len(w2i.keys())\n            w2i[joined_word] = l\n            i2w[l] = joined_word\n            vocab.append(joined_word)\nhyponyms = hyponyms[:-1]","metadata":{"execution":{"iopub.status.busy":"2023-05-03T19:59:35.551366Z","iopub.execute_input":"2023-05-03T19:59:35.553466Z","iopub.status.idle":"2023-05-03T19:59:35.565089Z","shell.execute_reply.started":"2023-05-03T19:59:35.553422Z","shell.execute_reply":"2023-05-03T19:59:35.563855Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"hyponyms[-10:]","metadata":{"execution":{"iopub.status.busy":"2023-05-03T20:03:45.459123Z","iopub.execute_input":"2023-05-03T20:03:45.460130Z","iopub.status.idle":"2023-05-03T20:03:45.467572Z","shell.execute_reply.started":"2023-05-03T20:03:45.460088Z","shell.execute_reply":"2023-05-03T20:03:45.466378Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['melodic_phrase',\n 'hot_issue',\n 'gavotte',\n 'antiphon',\n 'recapitulation',\n 'fugazi',\n 'nightshift',\n 'solfeggio',\n 'dance_pop',\n 'zydeco']"},"metadata":{}}]},{"cell_type":"code","source":"hypernyms = []\nfor line in gold:\n    line = line.lower()\n    line = line.split(\"\\t\")\n    temp_hypernyms = []\n    for word in line:\n        word = word.split(\" \")\n        if len(word)>1:\n            joined_word = \"\"\n            for w in word:\n                joined_word += w + \"_\"\n            joined_word = joined_word[:-1]\n            if joined_word not in w2i.keys():\n                l = len(w2i.keys())\n                w2i[joined_word] = l\n                i2w[l] = joined_word\n                vocab.append(joined_word)\n            temp_hypernyms.append(joined_word)\n        else:\n            temp_hypernyms.append(word[0])\n            joined_word = word[0]\n            if joined_word not in w2i.keys():\n                l = len(w2i.keys())\n                w2i[joined_word] = l\n                i2w[l] = joined_word\n                vocab.append(joined_word)\n    hypernyms.append(temp_hypernyms)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:18:48.093619Z","iopub.execute_input":"2023-05-03T08:18:48.093994Z","iopub.status.idle":"2023-05-03T08:18:48.112790Z","shell.execute_reply.started":"2023-05-03T08:18:48.093959Z","shell.execute_reply":"2023-05-03T08:18:48.111571Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"w2i['exodus']","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:18:48.712608Z","iopub.execute_input":"2023-05-03T08:18:48.715268Z","iopub.status.idle":"2023-05-03T08:18:48.723167Z","shell.execute_reply.started":"2023-05-03T08:18:48.715228Z","shell.execute_reply":"2023-05-03T08:18:48.722049Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"19507"},"metadata":{}}]},{"cell_type":"code","source":"all_hypernyms = set()\n\nfor line in hypernyms:\n    for word in line:\n        all_hypernyms.add(word)\n\nall_hypernyms = list(all_hypernyms)\n# all_hypernyms[:10]","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:18:49.565142Z","iopub.execute_input":"2023-05-03T08:18:49.565846Z","iopub.status.idle":"2023-05-03T08:18:49.572750Z","shell.execute_reply.started":"2023-05-03T08:18:49.565802Z","shell.execute_reply":"2023-05-03T08:18:49.570894Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"\n### vocab","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a function for finding negative hypernyms of given hyponyms\n# this function will return hyponym positive and negative hpyernyms in following manner\n# given hyponym - 'ayush'\n''' function should return - \n[\n\n    [['man'],['neg11','neg12','neg13','neg14','neg15']],\n    [['boy'],['neg21','neg22','neg23','neg24','neg25']],\n    [['person'],['neg31','neg32','neg33','neg34','neg35']],\n    [['student'],['neg41','neg42','neg43','neg44','neg45']],\n    \n    ]\n    \n    \n    '''\n\nnum_neg_hypernyms = 5\n\ndef pos_neg_hypernyms(hyponym):\n\n    try:\n        index_in_data = hyponyms.index(hyponym)\n        \n    except:\n        print(ind,len(hyponyms),hyponym)\n    \n    hypernyms_temp = hypernyms[index_in_data]\n    num_hypernyms = len(hypernyms_temp)\n    neg_hypernyms = []\n    for i in range(num_hypernyms*num_neg_hypernyms):\n        neg_h = all_hypernyms[random.randint(0,len(all_hypernyms)-1)]\n        while neg_h in neg_hypernyms or neg_h == hyponym or neg_h in hypernyms_temp: \n            neg_h = all_hypernyms[random.randint(0,len(all_hypernyms)-1)]\n            \n        neg_hypernyms.append(neg_h)\n    \n    ans = []\n    for i in range(num_hypernyms):\n        ans_temp = []\n        h_ind = w2i[hypernyms_temp[i]]\n        ans_temp.append([h_ind])\n        \n                    \n        neg_temp = []\n        for j in range(i*5,i*5+5):\n            neg_temp.append(w2i[neg_hypernyms[j]])\n            \n        ans_temp.append(neg_temp)\n        \n        ans.append(ans_temp)\n    return ans\n        ","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:18:51.423214Z","iopub.execute_input":"2023-05-03T08:18:51.423578Z","iopub.status.idle":"2023-05-03T08:18:51.434552Z","shell.execute_reply.started":"2023-05-03T08:18:51.423544Z","shell.execute_reply":"2023-05-03T08:18:51.433236Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"pos_neg_hypernyms(w2i['maliciousness'])","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:18:51.937865Z","iopub.execute_input":"2023-05-03T08:18:51.938645Z","iopub.status.idle":"2023-05-03T08:18:51.959327Z","shell.execute_reply.started":"2023-05-03T08:18:51.938604Z","shell.execute_reply":"2023-05-03T08:18:51.958084Z"},"trusted":true},"execution_count":32,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3921838859.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos_neg_hypernyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maliciousness'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyError\u001b[0m: 'maliciousness'"],"ename":"KeyError","evalue":"'maliciousness'","output_type":"error"}]},{"cell_type":"code","source":"print( hyponyms.index('maliciousness'))\nprint(hypernyms[0])\nprint(w2i['malignity'])","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:18:52.625660Z","iopub.execute_input":"2023-05-03T08:18:52.626046Z","iopub.status.idle":"2023-05-03T08:18:52.645604Z","shell.execute_reply.started":"2023-05-03T08:18:52.625995Z","shell.execute_reply":"2023-05-03T08:18:52.644074Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2740158286.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mhyponyms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maliciousness'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypernyms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'malignity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: 'maliciousness' is not in list"],"ename":"ValueError","evalue":"'maliciousness' is not in list","output_type":"error"}]},{"cell_type":"markdown","source":"# Step 1 -  Glove se embedding le rhe","metadata":{}},{"cell_type":"code","source":"# embed_dict = {}\n\n# with open('/kaggle/input/glove-embeddings/glove.6B.300d.txt','r') as f:\n#     for line in f:\n#         values = line.split()\n#         word = values[0]\n#         vector = np.asarray(values[1:],'float32')\n#         embed_dict[word]=vector\n\n# embed_dict['oov'] = np.zeros(300)\n\n\nf = open('/kaggle/input/word2vec/model.txt','r')\nword2vec_pretrained = f.read()\nword2vec_pretrained = word2vec_pretrained.split('\\n')\nword_emb = {}\nfor i,sent in tqdm(enumerate(word2vec_pretrained)):\n    if i == 0 or i == len(word2vec_pretrained)-1:\n        continue\n    sent = sent.split(' ')\n    word_tag = sent[0]\n    word_tag = word_tag.split('_')\n    word = word_tag[0]\n    tag = word_tag[1]\n    emb = sent[1:]\n    word_emb[word] = emb","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:18:53.897979Z","iopub.execute_input":"2023-05-03T08:18:53.899148Z","iopub.status.idle":"2023-05-03T08:19:05.752771Z","shell.execute_reply.started":"2023-05-03T08:18:53.899101Z","shell.execute_reply":"2023-05-03T08:19:05.751708Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"163475it [00:06, 23552.59it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"my_embed = torch.empty((len(w2i.keys()),300),dtype=torch.float32).to(device)\n\nfor i in tqdm(range(len(w2i.keys()))):\n    try:\n        my_embed[i] = tensor.torch(word_emb[i2w[i]])\n    except:\n        my_embed[i] = torch.randn(300) - 0.5\n#     my_embed.append(x)\n    \n# my_embed = np.array(my_embed)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:19:05.755165Z","iopub.execute_input":"2023-05-03T08:19:05.755898Z","iopub.status.idle":"2023-05-03T08:19:07.990988Z","shell.execute_reply.started":"2023-05-03T08:19:05.755858Z","shell.execute_reply":"2023-05-03T08:19:07.989822Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"100%|██████████| 69214/69214 [00:02<00:00, 31704.77it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(type(my_embed[0]))\nayush = torch.tensor(my_embed).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:19:07.992699Z","iopub.execute_input":"2023-05-03T08:19:07.993121Z","iopub.status.idle":"2023-05-03T08:19:08.000485Z","shell.execute_reply.started":"2023-05-03T08:19:07.993082Z","shell.execute_reply":"2023-05-03T08:19:07.999325Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"<class 'torch.Tensor'>\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model architecture","metadata":{}},{"cell_type":"code","source":"my_embed[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:19:08.003502Z","iopub.execute_input":"2023-05-03T08:19:08.004461Z","iopub.status.idle":"2023-05-03T08:19:08.020495Z","shell.execute_reply.started":"2023-05-03T08:19:08.004419Z","shell.execute_reply":"2023-05-03T08:19:08.019043Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"tensor([-2.3473, -0.1376,  1.3339, -0.1941, -0.0558, -0.9553, -0.2165, -0.7405,\n        -0.2102, -2.5986, -0.6938, -0.9715,  0.2765, -0.3417, -2.3303, -1.9035,\n         1.5834,  0.6114, -0.2227, -1.4244, -0.8406, -0.1344,  0.4327, -0.8914,\n        -0.0413, -1.9956,  0.4505, -1.9739, -0.0778, -1.5297, -1.2487, -1.7162,\n        -0.7949, -0.1387, -0.5110, -1.6256, -1.8286,  1.5264, -0.1992, -0.3642,\n        -1.0611, -1.0926, -0.1016,  0.1592, -1.3246,  0.1706, -0.8517, -0.8840,\n        -0.1951, -2.3112, -0.1781,  0.5027, -0.4036, -0.1619, -0.4024, -1.2881,\n         0.9208,  0.5303,  0.7317, -2.1539,  0.1457, -2.0435,  0.2250, -0.9976,\n         1.7259,  0.6078,  0.8222, -0.5802, -0.7488, -1.6067, -0.2956, -1.5322,\n         0.1158, -0.4531, -0.0584, -0.1054, -0.5861, -0.5074, -1.0755, -0.3392,\n        -2.1925, -1.3966,  0.3693, -0.4955,  0.0185, -0.3899,  0.9854, -0.0216,\n        -0.3865, -0.8611, -1.3445, -1.2779,  1.6939,  0.7684, -0.3829,  0.4310,\n        -0.5873, -1.6402, -0.2029, -1.3405, -1.4307, -0.5867, -1.1705, -1.5024,\n         0.4978, -2.7324, -0.0905, -1.6048,  0.9757,  0.7926,  0.1489, -0.2795,\n        -0.8229, -0.7579, -1.3784, -1.6733, -0.0505,  0.5498, -0.0472, -0.6539,\n         0.1205, -2.2458, -2.2122, -0.3166, -0.0396, -2.2709,  1.0287, -1.6048,\n        -1.1870, -0.8176,  0.0911,  0.1932, -1.0129, -2.2357,  1.1490, -1.3316,\n        -1.0308, -0.3766, -3.8988,  0.9288, -1.1564, -1.6406,  1.1839, -1.9293,\n         0.3960,  0.1032,  1.3405,  0.3981, -0.5530,  0.0245, -0.1373, -1.0875,\n        -2.5041, -1.0384, -1.5094,  1.4179, -1.4319,  0.8437, -0.4728,  0.1217,\n         0.4913, -1.6470, -0.2666, -1.0060,  0.2421,  1.1414,  1.7229,  0.0690,\n        -0.8962, -1.0260, -1.4064, -1.0508, -1.4981, -0.1517, -0.1269, -0.6240,\n        -0.4631, -0.6100, -2.8191,  0.5100, -0.4364, -1.7280, -0.4050, -0.4059,\n        -1.9759, -0.4931,  0.0237, -1.2290, -1.2716, -2.1641, -0.7519, -1.8223,\n        -0.0488, -1.7321,  0.9390, -1.7612, -0.5256, -0.2901, -0.1635,  0.0660,\n        -1.7159,  0.2212, -1.7098,  1.1821, -1.1979, -1.9230,  0.6803,  1.1052,\n        -1.6605, -1.7840,  0.0716, -0.1144, -1.2005, -0.3518,  0.1074, -0.3132,\n        -0.0160, -0.5157, -1.3254, -0.1286, -0.9183,  0.2666, -1.1750,  0.9105,\n        -0.1974,  0.0653, -0.4944,  0.4549,  0.6576,  0.3225, -0.3729,  0.4448,\n        -0.8882, -0.0896,  2.0282, -0.0277, -0.6332, -0.2645, -0.5923,  1.3140,\n        -1.9054,  0.4293, -1.1800, -0.5782, -1.1648, -0.7713, -1.8040, -1.4869,\n        -1.1538,  0.6362,  0.9446, -0.2005, -0.2820, -0.9570,  0.9527,  0.8793,\n         1.0823, -1.3128, -2.0066, -0.2463, -2.3245, -0.6532, -1.1732, -1.6623,\n         0.1883, -1.0914, -1.5171, -0.2553, -0.5511, -0.9474,  1.2135, -1.5945,\n        -1.1951, -0.5550,  0.0802, -0.4362, -0.9770, -1.9469, -0.4752,  0.2526,\n         0.4321,  0.7045, -0.2166, -1.1180, -1.9226, -0.2993, -1.7823, -0.6495,\n         0.1577,  0.0271, -0.1019,  0.1542,  0.9225, -0.5074, -0.3896,  0.6885,\n         0.5545, -0.6011,  1.4632, -1.1020], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"class w2v_HH_embeddings(nn.Module):\n    def __init__(self, vocab_size, embedding_size):\n        super(w2v_HH_embeddings, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_size)\n        self.embedding.weight.data.copy_(my_embed) #to do\n        \n        self.linear1 = nn.Linear(embedding_size, 1)\n        self.linear2 = nn.Linear(embedding_size, 1)\n        # self.sigmoid = nn.Sigmoid()\n\n    def forward(self, hyponym, hypernym, neg_hypernym):\n        # (bs,1) (bs,1) (bs,neg_sam)\n        hyponym_embeddings = self.embedding(hyponym) # bs,1,300\n        hypernym_embeddings = self.embedding(hypernym) # bs,1,300\n        neg_hypernym_embeddings = self.embedding(neg_hypernym) # bs,5,300\n        \n#         similarity between hyponym and true hypernym\n        pos_score = torch.mul(hyponym_embeddings, hypernym_embeddings) #bs,1,300\n        pos_score = torch.squeeze(pos_score, 1)#bs,300  \n        pos_score = self.linear1(pos_score)#bs,1        \n        pos_score = -F.logsigmoid(pos_score) #bs,1\n        pos_score = torch.squeeze(pos_score,1) #bs\n\n#         similarity between hyponym and true neg hypernym\n        hyponym_embeddingsT = torch.transpose(hyponym_embeddings, 1, 2) #bs,300, 1\n        neg_score = torch.bmm(neg_hypernym_embeddings, hyponym_embeddingsT) #bs,5,1\n        neg_score = torch.squeeze(neg_score, 2)#bs,5\n        neg_score = -F.logsigmoid(-neg_score) #bs,5\n        neg_score = torch.sum(neg_score,dim=1) # bs\n        total_score = torch.mean(pos_score + neg_score)\n        return total_score","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:19:08.021791Z","iopub.execute_input":"2023-05-03T08:19:08.022705Z","iopub.status.idle":"2023-05-03T08:19:08.033594Z","shell.execute_reply.started":"2023-05-03T08:19:08.022669Z","shell.execute_reply":"2023-05-03T08:19:08.032848Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"vocab_size = len(i2w.keys())\nepochs = 50\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:19:08.034799Z","iopub.execute_input":"2023-05-03T08:19:08.035635Z","iopub.status.idle":"2023-05-03T08:19:08.048663Z","shell.execute_reply.started":"2023-05-03T08:19:08.035590Z","shell.execute_reply":"2023-05-03T08:19:08.047549Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model = w2v_HH_embeddings(vocab_size,300)\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(),lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:19:08.051454Z","iopub.execute_input":"2023-05-03T08:19:08.051746Z","iopub.status.idle":"2023-05-03T08:19:08.267214Z","shell.execute_reply.started":"2023-05-03T08:19:08.051707Z","shell.execute_reply":"2023-05-03T08:19:08.266035Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Training the embeddings","metadata":{}},{"cell_type":"code","source":"print(len(w2i.keys()),len(vocab))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:19:08.272058Z","iopub.execute_input":"2023-05-03T08:19:08.274450Z","iopub.status.idle":"2023-05-03T08:19:08.282554Z","shell.execute_reply.started":"2023-05-03T08:19:08.274407Z","shell.execute_reply":"2023-05-03T08:19:08.281332Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"69214 69214\n","output_type":"stream"}]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"for epoch in range(epochs):\n    hypernym_batch = []\n    hyponym_batch = []\n    neg_hypernym_batch = []\n    running_loss = []\n    \n    for i,hyponym in tqdm(enumerate(hyponyms)):\n#         ind = w2i[hyponyms[i]]\n        temp = pos_neg_hypernyms(hyponym)\n        \n        for a_list in temp:\n            # (bs,1) (bs,1) (bs,neg_sam)\n            hyponym_batch.append([ind]) #bs*1\n            \n            hypernym_batch.append(a_list[0]) # bs*1\n            neg_hypernym_batch.append(a_list[1]) # bs*5\n            \n            if len(hyponym_batch) == batch_size:\n                a = torch.tensor(hyponym_batch).to(device) # bs*1\n                \n                b = torch.tensor(hypernym_batch).to(device) # bs*1\n                \n                c = torch.tensor(neg_hypernym_batch).to(device) # bs*5\n                \n                loss = model(a,b,c)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                running_loss.append(loss.item())\n                \n                hyponym_batch.clear()\n                hypernym_batch.clear()\n                neg_hypernym_batch.clear()\n                \n    epoch_loss = np.mean(running_loss)\n    print(\"training epoch_loss is\", epoch_loss)\n                \n#         a = torch.tensor(hyponym_batch)\n#         b = torch.tensor(hypernym_batch)\n#         c = torch.tensor(neg_hypernym_batch)\n#         similarity = model(a,b,c)\n''' function should return - \n[\n\n    [['man'],['neg11','neg12','neg13','neg14','neg15']],\n    [['boy'],['neg21','neg22','neg23','neg24','neg25']],\n    [['person'],['neg31','neg32','neg33','neg34','neg35']],\n    [['student'],['neg41','neg42','neg43','neg44','neg45']],\n    \n    ]\n    \n    \n    '''","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:19:08.283998Z","iopub.execute_input":"2023-05-03T08:19:08.285310Z","iopub.status.idle":"2023-05-03T08:20:06.196897Z","shell.execute_reply.started":"2023-05-03T08:19:08.285269Z","shell.execute_reply":"2023-05-03T08:20:06.195823Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"499it [00:01, 431.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 336.03765061322383\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 436.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 313.1902713551241\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 432.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 291.8517249612247\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 438.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 269.1547970042509\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 442.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 248.03088387882008\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 437.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 227.13322358972886\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 434.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 204.3816203397863\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 435.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 182.01185204001035\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 424.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 162.69990369011373\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 433.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 141.3122401966768\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 432.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 121.30799663768096\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 435.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 101.20090103149414\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 438.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 84.5836877710679\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 437.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 69.41216924330767\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 431.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 55.03534128525678\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 443.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 43.96806541891659\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 443.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 34.33574177237118\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 438.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 26.541035079956053\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 423.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 20.085487898658304\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 414.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 14.573886910606833\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 399.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 10.814496332056382\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 440.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 7.898683971517226\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 439.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 5.584952235221863\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 439.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 4.256281128350426\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 438.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 3.0173813285196527\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 436.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 2.1856285459855025\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 437.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 1.5370405879090814\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 423.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 1.1260290913283826\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 432.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.8013097006608458\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 438.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.6005954576108385\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 438.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.505729165213073\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 439.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.4913382186280454\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 440.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.3614407949587878\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 438.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.34079958696247026\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 439.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.2754429548047483\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 441.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.2503763465046444\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 437.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.2048667786478558\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 422.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.2052698367521824\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 440.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.14010505785015137\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 438.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.15102387710255297\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 438.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.10606016990838243\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 440.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.09949690085452269\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 441.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.06850692567360751\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 439.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.04045850287246353\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 439.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.021113137025660013\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 434.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.010848208074457943\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 422.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.007108109299203053\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 360.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.005947790813961011\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 440.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.005055907646687154\n","output_type":"stream"},{"name":"stderr","text":"499it [00:01, 438.87it/s]","output_type":"stream"},{"name":"stdout","text":"training epoch_loss is 0.004283288653994746\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"\" function should return - \\n[\\n\\n    [['man'],['neg11','neg12','neg13','neg14','neg15']],\\n    [['boy'],['neg21','neg22','neg23','neg24','neg25']],\\n    [['person'],['neg31','neg32','neg33','neg34','neg35']],\\n    [['student'],['neg41','neg42','neg43','neg44','neg45']],\\n    \\n    ]\\n    \\n    \\n    \""},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/hypernym-hyponym-embeddings_training.pt')","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:20:06.200174Z","iopub.execute_input":"2023-05-03T08:20:06.200483Z","iopub.status.idle":"2023-05-03T08:20:06.369438Z","shell.execute_reply.started":"2023-05-03T08:20:06.200455Z","shell.execute_reply":"2023-05-03T08:20:06.368321Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"saved_embeddings = {}\nfor i in tqdm(range(1,len(i2w.keys()))):#(len(index2word)):\n    word = i2w[i]\n    saved_embeddings[word] = model.embedding.weight[i].detach().cpu().numpy()\n\nwith open('hypernym-hyponym-embeddings_2B.pkl','wb') as f:\n    pickle.dump(saved_embeddings,f)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:20:16.739406Z","iopub.execute_input":"2023-05-03T08:20:16.739989Z","iopub.status.idle":"2023-05-03T08:20:20.449989Z","shell.execute_reply.started":"2023-05-03T08:20:16.739952Z","shell.execute_reply":"2023-05-03T08:20:20.448772Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"100%|██████████| 69213/69213 [00:02<00:00, 23812.00it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"parameters = {}\n\nparameters['vocab'] = vocab\nparameters['i2w'] = i2w\nparameters['w2i'] = w2i\nparameters['hypernyms'] = hypernyms\nparameters['hyponyms'] = hyponyms\n\nwith open('hypernym-hyponym-dictionaries_2B.pkl','wb') as f:\n    pickle.dump(parameters,f)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:20:25.146090Z","iopub.execute_input":"2023-05-03T08:20:25.146788Z","iopub.status.idle":"2023-05-03T08:20:25.189404Z","shell.execute_reply.started":"2023-05-03T08:20:25.146753Z","shell.execute_reply":"2023-05-03T08:20:25.188359Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"a = torch.tensor([[1,2,3]])\nb = torch.tensor([[1,1,1],[2,2,2]])\nans = torch.mul(b,a)\nprint(a)\nprint(b)\nprint(ans)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T13:49:58.873482Z","iopub.execute_input":"2023-04-28T13:49:58.873950Z","iopub.status.idle":"2023-04-28T13:49:58.883519Z","shell.execute_reply.started":"2023-04-28T13:49:58.873904Z","shell.execute_reply":"2023-04-28T13:49:58.882127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding = nn.Embedding(100, 30)\nx = torch.tensor([[5],[3],[4]])\nz = embedding(x)\ny = embedding(x)\nsim = torch.mul(z,y)\nsim = torch.squeeze(sim, 1)#bs,300\nsim = torch.sum(sim,dim = 1)\nprint(sim)\na = nn.Sigmoid()\nsim = a(torch.tensor([[-9]]))\nprint(sim.shape)\nprint(sim)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-28T15:25:16.685126Z","iopub.execute_input":"2023-04-28T15:25:16.685543Z","iopub.status.idle":"2023-04-28T15:25:16.700245Z","shell.execute_reply.started":"2023-04-28T15:25:16.685508Z","shell.execute_reply":"2023-04-28T15:25:16.699230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = torch.randn(10,5)\nb = torch.randn(10,5)\nprint(a.shape)\n\nprint(torch.sum(a,dim = 1).shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T05:59:13.151620Z","iopub.execute_input":"2023-04-29T05:59:13.153169Z","iopub.status.idle":"2023-04-29T05:59:13.163954Z","shell.execute_reply.started":"2023-04-29T05:59:13.153079Z","shell.execute_reply":"2023-04-29T05:59:13.161711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.random.rand(300) - 0.5\nx","metadata":{"execution":{"iopub.status.busy":"2023-05-01T16:37:26.679242Z","iopub.execute_input":"2023-05-01T16:37:26.679767Z","iopub.status.idle":"2023-05-01T16:37:26.691811Z","shell.execute_reply.started":"2023-05-01T16:37:26.679721Z","shell.execute_reply":"2023-05-01T16:37:26.690252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}