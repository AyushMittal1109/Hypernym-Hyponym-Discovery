{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nfrom math import log2\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import sent_tokenize\nimport random\nimport numpy as np\nfrom keras.models import load_model\nfrom sklearn.metrics import classification_report\nimport math","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASMaI2_SENSD","outputId":"c6ced464-a6cc-4621-feb2-67a5ca7e44b1","execution":{"iopub.status.busy":"2023-05-02T18:02:17.208013Z","iopub.execute_input":"2023-05-02T18:02:17.208422Z","iopub.status.idle":"2023-05-02T18:02:27.353607Z","shell.execute_reply.started":"2023-05-02T18:02:17.208390Z","shell.execute_reply":"2023-05-02T18:02:27.352574Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading preprocessed dictionaries and lists","metadata":{}},{"cell_type":"code","source":"import pickle\n\nwith open('/kaggle/input/inlp-project/hypernym-hyponym-dictionaries_training.pkl', 'rb') as f:\n    data = pickle.load(f)\n    \n    vocab_eng = data['vocab']\n    i2w_eng = data['i2w']\n    w2i_eng = data['w2i']\n    data_eng = data['hyponyms']\n    gold_eng = data['hypernyms']\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:02:27.355278Z","iopub.execute_input":"2023-05-02T18:02:27.355933Z","iopub.status.idle":"2023-05-02T18:02:27.643634Z","shell.execute_reply.started":"2023-05-02T18:02:27.355900Z","shell.execute_reply":"2023-05-02T18:02:27.642543Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Compute dictionary with key as hyponym and value as list of hypernyms ","metadata":{}},{"cell_type":"code","source":"def compute_hyponym_hypernyms(data,gold):\n  hyponym_classification = {}\n  hyponym_hypernyms = {}\n  for i in range(len(data)):\n    hyponym = data[i]\n    hypernyms = gold[i]\n    hyponym_hypernyms[hyponym] = hypernyms\n  return hyponym_hypernyms","metadata":{"id":"EktdpNu9YrA6","execution":{"iopub.status.busy":"2023-05-02T18:02:27.713224Z","iopub.execute_input":"2023-05-02T18:02:27.713724Z","iopub.status.idle":"2023-05-02T18:02:27.725307Z","shell.execute_reply.started":"2023-05-02T18:02:27.713696Z","shell.execute_reply":"2023-05-02T18:02:27.724517Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"hyponym_hypernyms_eng = compute_hyponym_hypernyms(data_eng,gold_eng)","metadata":{"id":"-t5FwCWX5aVe","execution":{"iopub.status.busy":"2023-05-02T18:02:27.726434Z","iopub.execute_input":"2023-05-02T18:02:27.726890Z","iopub.status.idle":"2023-05-02T18:02:27.745704Z","shell.execute_reply.started":"2023-05-02T18:02:27.726864Z","shell.execute_reply":"2023-05-02T18:02:27.744932Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Compute dictionary with key as hypernym and value as list of hyponyms ","metadata":{}},{"cell_type":"code","source":"def compute_hypernym_hyponyms(hyponym_hypernyms):\n\n  hypernym_hyponyms = {}\n  for i in hyponym_hypernyms:\n    hypernyms_list = hyponym_hypernyms[i]\n    for j in hypernyms_list:\n      if j in hypernym_hyponyms:\n        hypernym_hyponyms[j].append(i)\n      else:\n        hypernym_hyponyms[j] = [i]\n  for i in hyponym_hypernyms:\n    hypernyms_list = set(hyponym_hypernyms[i])\n    hyponym_hypernyms[i] = hypernyms_list\n  \n  return hypernym_hyponyms","metadata":{"id":"BGx9LiDebF31","execution":{"iopub.status.busy":"2023-05-02T18:02:27.776014Z","iopub.execute_input":"2023-05-02T18:02:27.776647Z","iopub.status.idle":"2023-05-02T18:02:27.786211Z","shell.execute_reply.started":"2023-05-02T18:02:27.776619Z","shell.execute_reply":"2023-05-02T18:02:27.785013Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"hypernym_hyponyms_eng = compute_hypernym_hyponyms(hyponym_hypernyms_eng)\n# hypernym_hyponyms_ital = compute_hypernym_hyponyms(hyponym_hypernyms_ital)\n# hypernym_hyponyms_span = compute_hypernym_hyponyms(hyponym_hypernyms_span)","metadata":{"id":"fhPns8Ju6XdA","execution":{"iopub.status.busy":"2023-05-02T18:02:27.787433Z","iopub.execute_input":"2023-05-02T18:02:27.787719Z","iopub.status.idle":"2023-05-02T18:02:27.808673Z","shell.execute_reply.started":"2023-05-02T18:02:27.787695Z","shell.execute_reply":"2023-05-02T18:02:27.807755Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Load pretrained Glove embeddings","metadata":{}},{"cell_type":"code","source":"# Glove Embeddings\n\nembed_dict = {}\n\nwith open('/kaggle/input/glove-embeddings/glove.6B.300d.txt','r') as f:\n  for line in f:\n    values = line.split()\n    word = values[0]\n    vector = np.asarray(values[1:],'float32')\n    embed_dict[word]=vector\n\nembed_dict['oov'] = np.zeros(300)\nglove_embeddings_eng = embed_dict","metadata":{"id":"A8lflwfiVrWn","execution":{"iopub.status.busy":"2023-05-02T18:02:27.866075Z","iopub.execute_input":"2023-05-02T18:02:27.866790Z","iopub.status.idle":"2023-05-02T18:02:58.618262Z","shell.execute_reply.started":"2023-05-02T18:02:27.866752Z","shell.execute_reply":"2023-05-02T18:02:58.617249Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Load custom trained with negative sampling word2vec embeddings","metadata":{}},{"cell_type":"code","source":"# Word2Vec pretrained embeddings further trained with hypernym negative sampling\n\nwith open('/kaggle/input/inlp-project/hypernym-hyponym-embeddings_training.pkl', 'rb') as f:\n    data = pickle.load(f)\n    \nword2vec_embeddings_eng = data","metadata":{"id":"RynMtREsWxoK","execution":{"iopub.status.busy":"2023-05-02T18:02:58.619626Z","iopub.execute_input":"2023-05-02T18:02:58.620018Z","iopub.status.idle":"2023-05-02T18:03:01.947175Z","shell.execute_reply.started":"2023-05-02T18:02:58.619983Z","shell.execute_reply":"2023-05-02T18:03:01.946109Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"queries_eng = data_eng","metadata":{"id":"wObDiY-hqegc","execution":{"iopub.status.busy":"2023-05-02T18:03:01.955275Z","iopub.execute_input":"2023-05-02T18:03:01.956091Z","iopub.status.idle":"2023-05-02T18:03:01.970295Z","shell.execute_reply.started":"2023-05-02T18:03:01.956062Z","shell.execute_reply":"2023-05-02T18:03:01.969189Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Compute co-hyponyms for given set of hyponyms","metadata":{}},{"cell_type":"code","source":"Q = []\nHq = []\nco_hyponyms_query = {}\n\n# query -> hyponym\nfor query in queries_eng:                            \n  # get hypernyms for a given hyponym \n  hypernyms_query = hyponym_hypernyms_eng[query]     \n  co_hyponyms = []\n  for hypernym in hypernyms_query:                   \n    # store all hyponyms of the hypernyms derived from above in the list \"co-hyponyms\" \n    for hyponym in hypernym_hyponyms_eng[hypernym]:\n        if hyponym != query:         \n            # append co-hyponym only if it is not the original hyponym\n            co_hyponyms.append(hyponym)\n  \n  #compute set of co-hyponyms list to get unique co-hyponyms\n  co_hyponyms_set = set(co_hyponyms)        \n  co_hyponyms_freq = {}\n  # compute frequency of each co-hyponym of a given hyponym and store in co_hyponyms_query\n  for co_hyponym in co_hyponyms_set:\n    freq = co_hyponyms.count(co_hyponym)\n    co_hyponyms_freq[co_hyponym] = freq\n\n  co_hyponyms_query[query] = co_hyponyms_freq","metadata":{"id":"2TuI9tsKWPNY","execution":{"iopub.status.busy":"2023-05-02T18:03:01.972368Z","iopub.execute_input":"2023-05-02T18:03:01.972945Z","iopub.status.idle":"2023-05-02T18:03:02.774776Z","shell.execute_reply.started":"2023-05-02T18:03:01.972915Z","shell.execute_reply":"2023-05-02T18:03:02.773608Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"co_hyponyms_query['pollution']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvbMYvD_YaGu","outputId":"1b200f01-a176-497c-a8a1-5a2ebbaa3bc6","execution":{"iopub.status.busy":"2023-05-02T18:03:02.776457Z","iopub.execute_input":"2023-05-02T18:03:02.776864Z","iopub.status.idle":"2023-05-02T18:03:02.783985Z","shell.execute_reply.started":"2023-05-02T18:03:02.776815Z","shell.execute_reply":"2023-05-02T18:03:02.783270Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'spotting': 1, 'light_pollution': 2, 'dirt': 3}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Compute cosine similarities","metadata":{}},{"cell_type":"code","source":"from numpy.linalg import norm\n\n# cosine similarity with pretrained glove embeddings\ndef calculate_cosine_similarity_glove(a,b):\n  A = np.zeros(300)\n  B = np.zeros(300)\n  if a in glove_embeddings_eng and b in glove_embeddings_eng:\n    A = glove_embeddings_eng[a]\n    B = glove_embeddings_eng[b]\n    cosine = np.dot(A,B)/(norm(A)*norm(B))\n#     print(cosine)\n    return 1-cosine\n  else:\n    return 0\n\n# cosine similarity with custom trained word2vec embeddings\ndef calculate_cosine_similarity_word2vec(a,b):\n  A = np.zeros(300)\n  B = np.zeros(300)\n  if a in word2vec_embeddings_eng and b in word2vec_embeddings_eng:\n    A = word2vec_embeddings_eng[a]\n    B = word2vec_embeddings_eng[b]\n    cosine = np.dot(A,B)/(norm(A)*norm(B))\n#     print(cosine)\n    return 1-cosine\n  else:\n    return 0","metadata":{"id":"K62LEIdwyXU-","execution":{"iopub.status.busy":"2023-05-02T18:03:02.785012Z","iopub.execute_input":"2023-05-02T18:03:02.785902Z","iopub.status.idle":"2023-05-02T18:03:02.795981Z","shell.execute_reply.started":"2023-05-02T18:03:02.785858Z","shell.execute_reply":"2023-05-02T18:03:02.795275Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"queries_eng_test = [data_eng[3]]\nfor q_test in queries_eng_test:\n    print(q_test)\n    print(gold_eng[3])","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:03:02.797211Z","iopub.execute_input":"2023-05-02T18:03:02.798374Z","iopub.status.idle":"2023-05-02T18:03:02.817582Z","shell.execute_reply.started":"2023-05-02T18:03:02.798327Z","shell.execute_reply":"2023-05-02T18:03:02.816513Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"tropical_storm\n['atmosphere', 'windstorm', 'violent_storm', 'air_current', 'atmospheric_state', 'density', 'current_of_air', 'storm_damage', 'atmospheric_phenomenon', 'storm', 'cyclone', 'natural_phenomenon', 'tempest', 'wind']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Compute final set of hypernyms for given set of hyponyms","metadata":{}},{"cell_type":"code","source":"def compute_final_set_of_hypernyms(embedding,queries):\n    \n    final_set_of_hypernyms_given_query = {}\n\n    for query in queries:\n      # compute scores of each co-hyponym for given hyponyms\n      # score is calculated using the formula: score = cosine_similarity(co-hyponym,hyponym) * frequency(co-hyponym)\n      scores = {}\n      for co_hyponym in co_hyponyms_query[query]:\n        if embedding == \"glove\":\n#             print(\"glove\")\n            score = calculate_cosine_similarity_glove(query,co_hyponym)\n            scores[co_hyponym] = score * co_hyponyms_query[query][co_hyponym]\n        else:\n#             print(\"word2vec\")\n            score = calculate_cosine_similarity_word2vec(query,co_hyponym)\n            scores[co_hyponym] = score * co_hyponyms_query[query][co_hyponym]\n            \n      # append top(most similar) 15 co-hyponyms in Q\n      Q = []\n      Q.append(query)\n      scores = sorted(scores.items(), key=lambda x:x[1], reverse = True)\n      count = 0\n      for i in scores:\n        if count == 15:\n          break\n        count += 1\n        Q.append(i[0])\n        \n      # Hq contains the list of hypernyms of the top 15 co-hyponyms\n      Hq = []\n      for q in Q:\n        Hq.extend(hyponym_hypernyms_eng[q])\n\n      # Compute frequency of hypernym as the count of hyponyms for which it is a hypernym \n      hypernym_freq = {}\n      for h in Hq:\n        c = 0\n        for cohyponym in co_hyponyms_query[query]:\n          if h in hyponym_hypernyms_eng[cohyponym]:\n            c += 1\n        hypernym_freq[h] = c\n\n      # Score each hypernym as follows: score = cosine_similarity(hypernym,original hyponym) * frequency(hypernym)^2\n      hypernym_scores = {}\n      Hq = set(Hq)\n#       print(Hq)\n      for h in Hq:\n        if embedding == \"glove\":\n            score = calculate_cosine_similarity_glove(query,h)\n        else:\n            score = calculate_cosine_similarity_word2vec(query,h)\n    \n        hypernym_scores[h] = score * hypernym_freq[h] * hypernym_freq[h]\n\n\n      # Take top 15 hypernyms as the final list of hypernyms for given set of hyponyms\n      final_set_hypernyms = []\n      hypernym_scores = sorted(hypernym_scores.items(), key=lambda x:x[1], reverse = True)\n      count = 0\n      for i in hypernym_scores:\n        if count == 15:\n          break\n        count += 1\n        final_set_hypernyms.append(i[0])\n      \n      final_set_of_hypernyms_given_query[query] = final_set_hypernyms\n      \n    return final_set_of_hypernyms_given_query,hypernym_scores","metadata":{"id":"PnpManmZy7tm","execution":{"iopub.status.busy":"2023-05-02T18:03:02.822738Z","iopub.execute_input":"2023-05-02T18:03:02.823453Z","iopub.status.idle":"2023-05-02T18:03:02.836484Z","shell.execute_reply.started":"2023-05-02T18:03:02.823409Z","shell.execute_reply":"2023-05-02T18:03:02.835300Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"final_list_hypernyms_glove,sg = compute_final_set_of_hypernyms(\"glove\",queries_eng_test)\nfinal_list_hypernyms_word2vec,sw = compute_final_set_of_hypernyms(\"word2vec\",queries_eng_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:03:02.837926Z","iopub.execute_input":"2023-05-02T18:03:02.838280Z","iopub.status.idle":"2023-05-02T18:03:02.863894Z","shell.execute_reply.started":"2023-05-02T18:03:02.838229Z","shell.execute_reply":"2023-05-02T18:03:02.862746Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(\"Hyponym:\",data_eng[3])\nprint()\nprint(\"Given hypernyms:\")\nprint(gold_eng[3])\nprint()\nprint(\"Hypernyms generated using Glove embeddings:\")\nprint(final_list_hypernyms_glove[q_test])\nprint()\nprint(\"Hypernyms generated using custom trained Word2Vec embeddings:\")\nprint(final_list_hypernyms_word2vec[q_test])","metadata":{"execution":{"iopub.status.busy":"2023-05-02T14:41:21.134747Z","iopub.execute_input":"2023-05-02T14:41:21.135097Z","iopub.status.idle":"2023-05-02T14:41:21.141357Z","shell.execute_reply.started":"2023-05-02T14:41:21.135068Z","shell.execute_reply":"2023-05-02T14:41:21.140459Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"\nHyponym: tropical_storm\n\nGiven hypernyms:\n['atmosphere', 'windstorm', 'violent_storm', 'air_current', 'atmospheric_state', 'density', 'current_of_air', 'storm_damage', 'atmospheric_phenomenon', 'storm', 'cyclone', 'natural_phenomenon', 'tempest', 'wind']\n\nHypernyms generated using Glove embeddings:\n['catastrophe', 'trouble', 'body_part', 'impinging', 'denseness', 'misfortune', 'risk', 'difference_of_opinion', 'ideal', 'windstorm', 'physiological_reaction', 'variable', 'musical_work', 'inclination', 'hostility']\n\nHypernyms generated using custom trained Word2Vec embeddings:\n['natural_phenomenon', 'phenomenon', 'physical_phenomenon', 'weather_condition', 'atmospheric_phenomenon', 'weather', 'atmospheric_condition', 'violent_storm', 'current_of_air', 'storm', 'wind', 'air_current', 'windstorm', 'hurricane', 'atmosphere']\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict(word):\n    if word not in data_eng:\n        return []\n    else:\n        ans = compute_final_set_of_hypernyms(\"word2vec\",[word])\n        return ans","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:05:07.109750Z","iopub.execute_input":"2023-05-02T18:05:07.110138Z","iopub.status.idle":"2023-05-02T18:05:07.116092Z","shell.execute_reply.started":"2023-05-02T18:05:07.110107Z","shell.execute_reply":"2023-05-02T18:05:07.114788Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"input_query = 'pollution'\nset_of_hypernyms,sim_scores = predict(input_query)\nprint(set_of_hypernyms[input_query])","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:06:48.338013Z","iopub.execute_input":"2023-05-02T18:06:48.338388Z","iopub.status.idle":"2023-05-02T18:06:48.345726Z","shell.execute_reply.started":"2023-05-02T18:06:48.338359Z","shell.execute_reply":"2023-05-02T18:06:48.344578Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"['excrement', 'poo', 'waste', 'dirtying', 'crap', 'sanitary_condition', 'trash', 'uncovering', 'soiling', 'environmental_pollution', 'body_waste', 'environmental_condition', 'waste_matter', 'discovery', 'excreta']\n","output_type":"stream"}]},{"cell_type":"code","source":"def write_to_file(final_list_hypernyms,filename):\n    f = open(filename, \"w\")\n    for i in final_list_hypernyms:\n      hyponym = i + \" -> {\"\n      f.write(hyponym)\n      hypernyms = \"\"\n      count = len(final_list_hypernyms[i])\n      c = 0\n      for j in final_list_hypernyms[i]:\n        if c != count-1:\n          hypernyms += j + \", \"\n        else:\n          hypernyms += j + \"}\" + \"\\n\"\n        c += 1\n      f.write(hypernyms)\n    f.close()","metadata":{"id":"bAi_yoVxXVW8","execution":{"iopub.status.busy":"2023-05-02T14:09:14.342207Z","iopub.execute_input":"2023-05-02T14:09:14.342600Z","iopub.status.idle":"2023-05-02T14:09:14.349959Z","shell.execute_reply.started":"2023-05-02T14:09:14.342564Z","shell.execute_reply":"2023-05-02T14:09:14.348419Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"write_to_file(final_list_hypernyms_glove,\"Hyponym_hypernyms_glove_eng.txt\")\nwrite_to_file(final_list_hypernyms_word2vec,\"Hyponym_hypernyms_word2vec_eng.txt\")","metadata":{"id":"IQDjjf8BxHgj","execution":{"iopub.status.busy":"2023-05-02T14:01:16.561183Z","iopub.execute_input":"2023-05-02T14:01:16.561496Z","iopub.status.idle":"2023-05-02T14:01:16.578752Z","shell.execute_reply.started":"2023-05-02T14:01:16.561468Z","shell.execute_reply":"2023-05-02T14:01:16.577464Z"},"trusted":true},"execution_count":32,"outputs":[]}]}