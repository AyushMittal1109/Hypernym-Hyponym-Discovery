{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom collections import Counter\n\nimport random\nimport json\nimport re\nfrom sklearn.manifold import TSNE\nfrom scipy import spatial\nimport matplotlib.pyplot as plt\nimport pickle\nimport copy\nfrom tqdm import tqdm\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:12:14.977916Z","iopub.execute_input":"2023-05-02T18:12:14.979003Z","iopub.status.idle":"2023-05-02T18:12:14.988778Z","shell.execute_reply.started":"2023-05-02T18:12:14.978966Z","shell.execute_reply":"2023-05-02T18:12:14.987647Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7766a1a81e30>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"# no of projection matrices\nk = 24\n\n# no of dimentions in embedding\ndim = 300\n\n# no of negative samples\nneg_sample_count = 5\n\n# learning rate\nlr = 0.001\n\nbatch_size = 32\n\nvocab_size = len(vocab)\n\n# 1A 2A 2B\nsubtask = \"1A\"\n\n# training test\nphase = \"training\"\n\n# datafile\ndataFilePath = f\"/kaggle/input/inlp-project/{subtask}.english.{phase}.data.txt\"\n\n# goldfile\ngoldFilePath = f\"/kaggle/input/inlp-project/{subtask}.english.{phase}.gold.txt\"\n\n# vocab\nvocabFilePath = f\"/kaggle/input/inlp-project/{subtask}.english.vocabulary.txt\"\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:21:04.995727Z","iopub.execute_input":"2023-05-02T18:21:04.996114Z","iopub.status.idle":"2023-05-02T18:21:05.002842Z","shell.execute_reply.started":"2023-05-02T18:21:04.996082Z","shell.execute_reply":"2023-05-02T18:21:05.001882Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Data loading","metadata":{}},{"cell_type":"code","source":"file = open(f\"/kaggle/input/inlp-project/hypernym-hyponym-dictionaries_{subtask}.pkl\",'rb')\nparameters = pickle.load(file)\nfile.close()\n\nvocab = parameters['vocab']\nw2i = parameters['w2i']\ni2w = parameters['i2w']\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:36:53.502601Z","iopub.execute_input":"2023-05-02T18:36:53.502977Z","iopub.status.idle":"2023-05-02T18:36:53.700804Z","shell.execute_reply.started":"2023-05-02T18:36:53.502944Z","shell.execute_reply":"2023-05-02T18:36:53.699903Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# considering preprocesses data like lower and three gram, bi gram, one gram\n\ndata = []\nwith open(dataFilePath) as dataset:\n    for line in tqdm(dataset):\n        line = line.lower()\n        line = line.split('\\t')\n        data.append(line[0])\n        \nprint(len(data))","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:22:31.452714Z","iopub.execute_input":"2023-05-02T18:22:31.453084Z","iopub.status.idle":"2023-05-02T18:22:31.465789Z","shell.execute_reply.started":"2023-05-02T18:22:31.453053Z","shell.execute_reply":"2023-05-02T18:22:31.464647Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"1500it [00:00, 595218.16it/s]","output_type":"stream"},{"name":"stdout","text":"1500\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"gold = []\nwith open(goldFilePath) as dataset:\n    for line in tqdm(dataset):\n        line = line.lower()\n        line = line.strip()\n        line = line.split('\\t')\n        gold.append(line)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:22:40.556374Z","iopub.execute_input":"2023-05-02T18:22:40.556749Z","iopub.status.idle":"2023-05-02T18:22:40.572424Z","shell.execute_reply.started":"2023-05-02T18:22:40.556711Z","shell.execute_reply":"2023-05-02T18:22:40.571541Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"1500it [00:00, 402267.01it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"class HHD(nn.Module):\n    def __init__(self, vocab_size, embedding_size):\n        super(HHD, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_size)\n#         self.embedding.weight.data.copy_(trained_embeddings) #to do\n\n        self.output = nn.Linear(k, 1)\n        \n        var = 2 / (dim + dim)\n        \n        # Initialize projection matrices using scheme from Glorot & Bengio (2008).\n        \n        self.proj_mats = torch.zeros([k, dim, dim], dtype=torch.float32).to(device)\n        # Fills self tensor with elements samples from the normal distribution parameterized by mean and std.\n        self.proj_mats.normal_(0, var)\n        # mat_data is of size k*dim*dim\n        # finally mat_data is k*dim*dim matrix ie k projection matrices, each matric is populated with random value\n        # diagonal elements will be 1+random value and other will be 0+random value and random value will range 0 and var\n        self.proj_mats += torch.cat([torch.eye(dim, ).unsqueeze(0) for _ in range(k)]).to(device)\n        self.sigmoid = nn.Sigmoid()\n        \n#     def similarity(self,query, cand_hypernym):\n#         query = self.embedding(query) #1*d\n#         cand_hypernymT = self.embedding(cand_hypernym) #1*d\n        \n#         #proj is of dim d*d, q is 1*d\n#         qT = torch.transpose(query,0,1).to(device) # d*1\n#         projT = torch.matmul(self.proj_mats,qT).to(device) #k*d*d X d*1 = k*d*1\n#         projT = torch.squeeze(projT,2).to(device) #k*d\n#         proj = torch.transpose(projT,0,1).to(device) #d*k\n        \n#         # find similarity between query and candidate \n#         cand_hypernym = torch.transpose(cand_hypernymT,0,1) #d*1\n#         simPosHyper = torch.matmul(projT,cand_hypernym).to(device) #k*d x d*1 = k*1\n#         simPosHyper = torch.squeeze(simPosHyper,1) # k\n#         simPos = self.output(simPosHyper) # 1\n        \n#         return simPos\n    \n    def similarity(self,query, cand_hypernym,bs):\n        query = self.embedding(query) #1*d\n        cand_hypernymT = self.embedding(cand_hypernym) #bs*d\n        \n        #proj is of dim d*d, q is 1*d\n        qT = torch.transpose(query,0,1).to(device) # d*1\n        projT = torch.matmul(self.proj_mats,qT).to(device) #k*d*d X d*1 = k*d*1\n        projT = torch.squeeze(projT,2).to(device) #k*d\n        proj = torch.transpose(projT,0,1).to(device) #d*k\n        \n        # find similarity between query and candidate \n        cand_hypernym = torch.transpose(cand_hypernymT,0,1) #d*bs\n        simPosHyper = torch.matmul(projT,cand_hypernym).to(device) #k*d x d*bs = k*bs\n#         simPosHyper = torch.squeeze(simPosHyper,1) # k\n        simPosHyper = torch.transpose(simPosHyper,0,1) # bs*k\n        simPos = self.output(simPosHyper) # bs*1\n        simPos = self.sigmoid(simPos) #bs*1\n        \n        return simPos\n        \n\n    def forward(self, query, cand_hypernym, neg_hypernyms ):\n        # query - 255 , cand_hypernym - 255, neg_hypernyms - 255*5\n        # getting embeddings of required entities\n        query = self.embedding(query) #bs*d\n        cand_hypernymT = self.embedding(cand_hypernym) #bs*d\n        neg_hypernymsT = self.embedding(neg_hypernyms) #bs*ns*d\n        \n        query = torch.unsqueeze(query,2) # bs*d*1\n\n#         batch_proj = torch.empty((batch_size,k,dim),dtype=torch.float32).to(device)\n#         for i,q in enumerate(query):\n#             # q is tensor of size d*1\n#             projT = torch.matmul(self.proj_mats,q).to(device) # k*d*d X d*1 = k*d*1\n#             projT = torch.squeeze(projT,2) # k*d\n#             batch_proj[i] = projT #bs*k*d\n            \n        batch_proj = torch.tensor([]).to(device)\n        for i,q in enumerate(query):\n            projT = torch.matmul(self.proj_mats,q).to(device) # k*d*d X d*1 = k*d*1\n            projT = torch.squeeze(projT,2) # k*d\n            projT = projT.reshape([-1])\n            batch_proj = torch.cat((batch_proj,projT))\n        \n        batch_proj = batch_proj.reshape([-1,k,dim])\n        \n        \n        # find similarity between query and candidate \n        cand_hypernym = torch.unsqueeze(cand_hypernymT,2) #bs*d*1\n        simPos = torch.bmm(batch_proj,cand_hypernym) #bs*k*d x bs*d*1 = bs*k*1\n        simPos = torch.squeeze(simPos,2) #bs*k\n        simPosOutput = self.output(simPos) #bs*1\n#         simPosOutput = self.sigmoid(simPosOutput)\n        \n        \n        # a step from above\n        # find similarity between query and negative samples\n        batch_projT = torch.transpose(batch_proj,1,2) #bs*d*k\n        simNegs = torch.bmm(neg_hypernymsT,batch_projT) #bs*ns*d x bs*d*k = bs*ns*k\n        simNegsOutput = self.output(simNegs) #bs*ns*1\n        simNegsOutput = torch.squeeze(simNegsOutput,2) #bs*ns\n#         simNegsOutput = self.sigmoid(simNegsOutput)\n        \n        \n        \n        # simPos - bs*1, simNegs - bs*ns\n        return simPosOutput,simNegsOutput\n    \n#     ///////////////////////////////////////////////////////////////////////////////////////\n        # getting embeddings of required entities\n        query = self.embedding(query)\n        cand_hypernymT = self.embedding(cand_hypernym) #1*d\n        neg_hypernymsT = self.embedding(neg_hypernyms) #ns*1*d\n        \n        #proj is of dim d*d, q is 1*d\n        qT = torch.transpose(query,0,1) # d*1\n        projT = torch.matmul(self.proj_mats,qT).to(device)\n        projT = torch.squeeze(projT,2) # k*d*d X d*1 = k*d*1\n        proj = torch.transpose(projT,0,1) #k*d\n        \n        # find similarity between query and candidate \n        cand_hypernym = torch.transpose(cand_hypernymT,0,1) #d*1\n        simPosHyper = torch.matmul(proj,cand_hypernym).to(device) #k*d x d*1 = k*1\n        simPosHyper = torch.squeeze(simPosHyper,1) # k\n        simPos = output(simPosHyper) # 1\n        \n        # find similarity between query and negative samples\n        #neg_hypernyms = torch.transpose(neg_hypernymsT,1,2) # ns*d*1\n        simNegHypersT = torch.matmul(neg_hypernymsT,projT).to(device) # ns*1*d x d*k= ns*1*k\n        simNegHypers = torch.transpose(simNegHypersT,1,2) # ns*k*1\n        simNegHypers = torch.squeeze(simNegHypers,2) # ns*k\n        simNegs = output(simNegHypers) # ns*1\n        simNegs = torch.squeeze(simNegs,1) # ns\n        \n        return simPos,simNegs\n    \n            ","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:22:56.578580Z","iopub.execute_input":"2023-05-02T18:22:56.578962Z","iopub.status.idle":"2023-05-02T18:22:56.601095Z","shell.execute_reply.started":"2023-05-02T18:22:56.578925Z","shell.execute_reply":"2023-05-02T18:22:56.600027Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Projection model","metadata":{}},{"cell_type":"code","source":"projection_model = HHD(vocab_size,dim)\nprojection_model.to(device)\nprojection_model = torch.load(\"/kaggle/input/inlp-project/HH_Projection_model_1A.pt\")\nprojection_model.eval()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:37:11.038790Z","iopub.execute_input":"2023-05-02T18:37:11.039152Z","iopub.status.idle":"2023-05-02T18:37:14.361835Z","shell.execute_reply.started":"2023-05-02T18:37:11.039121Z","shell.execute_reply":"2023-05-02T18:37:14.360911Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"HHD(\n  (embedding): Embedding(219246, 300)\n  (output): Linear(in_features=24, out_features=1, bias=True)\n  (sigmoid): Sigmoid()\n)"},"metadata":{}}]},{"cell_type":"code","source":"'''\n    predict function will take a query, a word and will return list of \n    100 closest words according to projection learning model ie supervised learning\n'''\ndef predict(query):\n    \n    try:\n        q = torch.tensor([w2i[query]]).to(device)\n    except:\n        return \"word not found in vocab\"\n    \n    closest_hypernyms = [] \n    \n    h = torch.tensor(list(range(1,vocab_size))).to(device)\n    s = projection_model.similarity(q,h,h.shape[0]) #bs*1\n\n    for i in range(1,vocab_size):\n        closest_hypernyms.append([float(s[i-1]),vocab[i]])\n    closest_hypernyms.sort(reverse=True)\n    answer = []\n    \n    l = 100\n    if l>len(closest_hypernyms):\n        l = len(closest_hypernyms)\n    \n    for i in range(l):\n        answer.append(closest_hypernyms[i][1])\n        \n    return answer","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:38:50.600870Z","iopub.execute_input":"2023-05-02T18:38:50.601708Z","iopub.status.idle":"2023-05-02T18:38:50.608786Z","shell.execute_reply.started":"2023-05-02T18:38:50.601670Z","shell.execute_reply":"2023-05-02T18:38:50.607821Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"predict(\"figure\")","metadata":{"execution":{"iopub.status.busy":"2023-05-02T18:37:32.401473Z","iopub.execute_input":"2023-05-02T18:37:32.401829Z","iopub.status.idle":"2023-05-02T18:37:36.448875Z","shell.execute_reply.started":"2023-05-02T18:37:32.401796Z","shell.execute_reply":"2023-05-02T18:37:36.447840Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"['foodborne_illness',\n 'supraocular',\n 'incurrence',\n 'chinaberry_tree',\n 'vegetate',\n 'schwalbea',\n 'dialectal',\n 'iodine-131',\n 'style_of_architecture',\n 'vedic',\n 'inlight',\n 'losel',\n 'semi-dry',\n 'haliotis_rufescens',\n 'sawgrass',\n 'naslund',\n 'unvaluable',\n 'fly',\n 'morphotactics',\n '185',\n 'orchard',\n 'quinquennial',\n 'housewifization',\n 'korotkoff_sounds',\n 'monoarticular',\n 'tryptamine',\n 'pi',\n 'string_along',\n 'nonlinear_optics',\n 'microbotryum',\n 'sister-in-laws',\n 'sodium_stibogluconate',\n 'overking',\n 'blind_person',\n 'spener',\n 'ferromagnetic',\n 'archi',\n 'bloodthirstily',\n 'langenbach',\n 'botrytis_cinerea',\n 'batrachospermum',\n 'apocrine_gland',\n 'abscond',\n 'buenoa',\n 'meeuwsen',\n 'second_deck',\n 'sulzberger',\n 'change_course',\n 'population_commission',\n 'nusselt_number',\n 'vicar',\n 'sulh',\n 'charax',\n 'moocher',\n 'garishness',\n 'racquet',\n 'pillow_talk',\n 'catenet',\n 'nationalist_leader',\n 'shot_hole',\n 'myrtaceae',\n 'splicer',\n 'hemicrania',\n 'practical_application',\n 'redressive',\n 'isak',\n 'pehlevi',\n 'observational',\n 'argive',\n 'villeroy',\n 'temperateness',\n 'unwrite',\n 'huguette',\n 'beauvoir',\n 'sulfite_oxidase',\n 'reading_program',\n 'chupacabras',\n 'meanderingly',\n 'soft_corn',\n 'unconsidered',\n 'himes',\n 'f-ratio',\n 'responsive',\n 'salary_increase',\n 'iraki',\n 'leaf_lard',\n 'puppyism',\n 'gallo-roman',\n 'pot_plant',\n 'macropore',\n 'opiated',\n 'outflowing',\n 'sloshed',\n 'oxygen_deficit',\n 'bystander',\n 'amphibious_warfare',\n 'tilt-top_table',\n 'looseness',\n 'fire_engine_red',\n 'ooda_loop']"},"metadata":{}}]},{"cell_type":"code","source":"print(vo)","metadata":{},"execution_count":null,"outputs":[]}]}