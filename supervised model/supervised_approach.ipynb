{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMPORTS","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom collections import Counter\nimport random\nimport json\nimport re\nfrom sklearn.manifold import TSNE\nfrom scipy import spatial\nimport matplotlib.pyplot as plt\nimport pickle\nimport copy\nfrom tqdm import tqdm\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:48:59.592532Z","iopub.execute_input":"2023-05-03T10:48:59.593022Z","iopub.status.idle":"2023-05-03T10:48:59.606678Z","shell.execute_reply.started":"2023-05-03T10:48:59.592977Z","shell.execute_reply":"2023-05-03T10:48:59.605639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file = open(\"/kaggle/input/inlp-project/hypernym-hyponym-dictionaries_2B.pkl\",'rb')\nparameters = pickle.load(file)\nfile.close()\n\nvocab = parameters['vocab']\nword2index = parameters['w2i']\nindex2word = parameters['i2w']\n","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:49:01.647581Z","iopub.execute_input":"2023-05-03T10:49:01.648328Z","iopub.status.idle":"2023-05-03T10:49:01.684522Z","shell.execute_reply.started":"2023-05-03T10:49:01.648291Z","shell.execute_reply":"2023-05-03T10:49:01.683523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(word2index[\"bagpipe\"])","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:49:04.388198Z","iopub.execute_input":"2023-05-03T10:49:04.389220Z","iopub.status.idle":"2023-05-03T10:49:04.395865Z","shell.execute_reply.started":"2023-05-03T10:49:04.389170Z","shell.execute_reply":"2023-05-03T10:49:04.394703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"# no of projection matrices\nk = 24\n\n# no of dimentions in embedding\ndim = 300\n\n# no of negative samples\nneg_sample_count = 5\n\n# learning rate\nlr = 0.001\n\nbatch_size = 32\n\nvocab_size = len(vocab)\n\nphase = \"training\"\nsubtask = \"2B.music\"\n\n# datafile\ndataFilePath = f\"/kaggle/input/inlp-project/{subtask}.{phase}.data.txt\"\n\n# goldfile\ngoldFilePath = f\"/kaggle/input/inlp-project/{subtask}.{phase}.gold.txt\"\n\n# vocab\nvocabFilePath = f\"/kaggle/input/inlp-project/{subtask}.vocabulary.txt\"\n","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:49:12.473569Z","iopub.execute_input":"2023-05-03T10:49:12.474360Z","iopub.status.idle":"2023-05-03T10:49:12.482778Z","shell.execute_reply.started":"2023-05-03T10:49:12.474321Z","shell.execute_reply":"2023-05-03T10:49:12.481658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vocab = []\n# with open(vocabFilePath) as dataset:\n#     for line in tqdm(dataset):\n# #         print(line)\n#         line = line.split('\\t')\n#         vocab.append(line[0][:-1])\n# vocab_size = len(vocab)\n# print(vocab[:20],vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:49:13.153019Z","iopub.execute_input":"2023-05-03T10:49:13.153705Z","iopub.status.idle":"2023-05-03T10:49:13.158245Z","shell.execute_reply.started":"2023-05-03T10:49:13.153668Z","shell.execute_reply":"2023-05-03T10:49:13.157002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# word2index = {}\n# index2word = {}\n\n# word2index['UNK'] = 0\n# index2word[0] = 'UNK'\n# for i,word in enumerate(vocab):\n#     word2index[word] = i+1\n#     index2word[i] = word\n    \n# print(list(word2index.keys())[:20])","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:49:13.711428Z","iopub.execute_input":"2023-05-03T10:49:13.712536Z","iopub.status.idle":"2023-05-03T10:49:13.717397Z","shell.execute_reply.started":"2023-05-03T10:49:13.712487Z","shell.execute_reply":"2023-05-03T10:49:13.716310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# considering preprocesses data like lower and three gram, bi gram, one gram\n\ndata = []\nwith open(dataFilePath) as dataset:\n    for line in tqdm(dataset):\n        line = line.lower()\n        line = line.split('\\t')\n        data.append(line[0])\n        \nprint(len(data))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:49:15.674303Z","iopub.execute_input":"2023-05-03T10:49:15.674716Z","iopub.status.idle":"2023-05-03T10:49:15.687257Z","shell.execute_reply.started":"2023-05-03T10:49:15.674681Z","shell.execute_reply":"2023-05-03T10:49:15.686151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gold = []\nwith open(goldFilePath) as dataset:\n    for line in tqdm(dataset):\n        line = line.lower()\n        line = line.strip()\n        line = line.split('\\t')\n        gold.append(line)\n        \nprint(gold[:20])","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:49:29.935164Z","iopub.execute_input":"2023-05-03T10:49:29.936101Z","iopub.status.idle":"2023-05-03T10:49:29.950985Z","shell.execute_reply.started":"2023-05-03T10:49:29.936049Z","shell.execute_reply":"2023-05-03T10:49:29.949709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_hyponym_hypernyms(data_train_sent,gold_train_sent):\n    hyponym_hypernyms = {}\n    for i in range(len(data_train_sent)):\n        hyponym = data_train_sent[i]\n        hypernyms = gold_train_sent[i]\n        hyponym_hypernyms[hyponym] = hypernyms\n    return hyponym_hypernyms","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:49:51.643077Z","iopub.execute_input":"2023-05-03T10:49:51.643689Z","iopub.status.idle":"2023-05-03T10:49:51.649150Z","shell.execute_reply.started":"2023-05-03T10:49:51.643650Z","shell.execute_reply":"2023-05-03T10:49:51.648015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyponym_hypernyms = compute_hyponym_hypernyms(data,gold)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:49:53.027087Z","iopub.execute_input":"2023-05-03T10:49:53.027460Z","iopub.status.idle":"2023-05-03T10:49:53.032856Z","shell.execute_reply.started":"2023-05-03T10:49:53.027426Z","shell.execute_reply":"2023-05-03T10:49:53.031624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL ARCHITECTURE","metadata":{}},{"cell_type":"markdown","source":"# loading embeddings","metadata":{}},{"cell_type":"code","source":"file = open(\"/kaggle/input/inlp-project/hypernym-hyponym-embeddings_2B.pkl\",'rb')\nembedding = pickle.load(file)\nfile.close()\n\ntrained_embeddings = torch.randn(dim).to(device)\n\nfor word in tqdm(vocab[1:]):\n    x = torch.from_numpy(embedding[word]).to(device)\n    x = x.reshape([-1])\n    trained_embeddings = torch.cat((trained_embeddings,x))\ntrained_embeddings = trained_embeddings.reshape([-1,dim])\n# trained_embeddings = torch.empty((vocab_size, dim),dtype=torch.float32).to(device)\n# for i,word in tqdm(enumerate(vocab)):\n#     trained_embeddings[i] = torch.from_numpy(embedding[word]).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:50:21.256662Z","iopub.execute_input":"2023-05-03T10:50:21.257037Z","iopub.status.idle":"2023-05-03T10:50:35.175773Z","shell.execute_reply.started":"2023-05-03T10:50:21.257004Z","shell.execute_reply":"2023-05-03T10:50:35.174652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HHD(nn.Module):\n    def __init__(self, vocab_size, embedding_size):\n        super(HHD, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_size)\n        self.embedding.weight.data.copy_(trained_embeddings) #to do\n\n        self.output = nn.Linear(k, 1)\n        \n        var = 2 / (dim + dim)\n        \n        # Initialize projection matrices using scheme from Glorot & Bengio (2008).\n        \n        self.proj_mats = torch.zeros([k, dim, dim], dtype=torch.float32).to(device)\n        # Fills self tensor with elements samples from the normal distribution parameterized by mean and std.\n        self.proj_mats.normal_(0, var)\n        # mat_data is of size k*dim*dim\n        # finally mat_data is k*dim*dim matrix ie k projection matrices, each matric is populated with random value\n        # diagonal elements will be 1+random value and other will be 0+random value and random value will range 0 and var\n        self.proj_mats += torch.cat([torch.eye(dim, ).unsqueeze(0) for _ in range(k)]).to(device)\n        self.sigmoid = nn.Sigmoid()\n        \n#     def similarity(self,query, cand_hypernym):\n#         query = self.embedding(query) #1*d\n#         cand_hypernymT = self.embedding(cand_hypernym) #1*d\n        \n#         #proj is of dim d*d, q is 1*d\n#         qT = torch.transpose(query,0,1).to(device) # d*1\n#         projT = torch.matmul(self.proj_mats,qT).to(device) #k*d*d X d*1 = k*d*1\n#         projT = torch.squeeze(projT,2).to(device) #k*d\n#         proj = torch.transpose(projT,0,1).to(device) #d*k\n        \n#         # find similarity between query and candidate \n#         cand_hypernym = torch.transpose(cand_hypernymT,0,1) #d*1\n#         simPosHyper = torch.matmul(projT,cand_hypernym).to(device) #k*d x d*1 = k*1\n#         simPosHyper = torch.squeeze(simPosHyper,1) # k\n#         simPos = self.output(simPosHyper) # 1\n        \n#         return simPos\n    \n    def similarity(self,query, cand_hypernym,bs):\n        query = self.embedding(query) #1*d\n        cand_hypernymT = self.embedding(cand_hypernym) #bs*d\n        \n        #proj is of dim d*d, q is 1*d\n        qT = torch.transpose(query,0,1).to(device) # d*1\n        projT = torch.matmul(self.proj_mats,qT).to(device) #k*d*d X d*1 = k*d*1\n        projT = torch.squeeze(projT,2).to(device) #k*d\n        proj = torch.transpose(projT,0,1).to(device) #d*k\n        \n        # find similarity between query and candidate \n        cand_hypernym = torch.transpose(cand_hypernymT,0,1) #d*bs\n        simPosHyper = torch.matmul(projT,cand_hypernym).to(device) #k*d x d*bs = k*bs\n#         simPosHyper = torch.squeeze(simPosHyper,1) # k\n        simPosHyper = torch.transpose(simPosHyper,0,1) # bs*k\n        simPos = self.output(simPosHyper) # bs*1\n        simPos = self.sigmoid(simPos) #bs*1\n        \n        return simPos\n        \n\n    def forward(self, query, cand_hypernym, neg_hypernyms ):\n        # query - 255 , cand_hypernym - 255, neg_hypernyms - 255*5\n        # getting embeddings of required entities\n        query = self.embedding(query) #bs*d\n        cand_hypernymT = self.embedding(cand_hypernym) #bs*d\n        neg_hypernymsT = self.embedding(neg_hypernyms) #bs*ns*d\n        \n        query = torch.unsqueeze(query,2) # bs*d*1\n\n#         batch_proj = torch.empty((batch_size,k,dim),dtype=torch.float32).to(device)\n#         for i,q in enumerate(query):\n#             # q is tensor of size d*1\n#             projT = torch.matmul(self.proj_mats,q).to(device) # k*d*d X d*1 = k*d*1\n#             projT = torch.squeeze(projT,2) # k*d\n#             batch_proj[i] = projT #bs*k*d\n            \n        batch_proj = torch.tensor([]).to(device)\n        for i,q in enumerate(query):\n            projT = torch.matmul(self.proj_mats,q).to(device) # k*d*d X d*1 = k*d*1\n            projT = torch.squeeze(projT,2) # k*d\n            projT = projT.reshape([-1])\n            batch_proj = torch.cat((batch_proj,projT))\n        \n        batch_proj = batch_proj.reshape([-1,k,dim])\n        \n        \n        # find similarity between query and candidate \n        cand_hypernym = torch.unsqueeze(cand_hypernymT,2) #bs*d*1\n        simPos = torch.bmm(batch_proj,cand_hypernym) #bs*k*d x bs*d*1 = bs*k*1\n        simPos = torch.squeeze(simPos,2) #bs*k\n        simPosOutput = self.output(simPos) #bs*1\n#         simPosOutput = self.sigmoid(simPosOutput)\n        \n        \n        # a step from above\n        # find similarity between query and negative samples\n        batch_projT = torch.transpose(batch_proj,1,2) #bs*d*k\n        simNegs = torch.bmm(neg_hypernymsT,batch_projT) #bs*ns*d x bs*d*k = bs*ns*k\n        simNegsOutput = self.output(simNegs) #bs*ns*1\n        simNegsOutput = torch.squeeze(simNegsOutput,2) #bs*ns\n#         simNegsOutput = self.sigmoid(simNegsOutput)\n        \n        \n        \n        # simPos - bs*1, simNegs - bs*ns\n        return simPosOutput,simNegsOutput\n    \n#     ///////////////////////////////////////////////////////////////////////////////////////\n        # getting embeddings of required entities\n        query = self.embedding(query)\n        cand_hypernymT = self.embedding(cand_hypernym) #1*d\n        neg_hypernymsT = self.embedding(neg_hypernyms) #ns*1*d\n        \n        #proj is of dim d*d, q is 1*d\n        qT = torch.transpose(query,0,1) # d*1\n        projT = torch.matmul(self.proj_mats,qT).to(device)\n        projT = torch.squeeze(projT,2) # k*d*d X d*1 = k*d*1\n        proj = torch.transpose(projT,0,1) #k*d\n        \n        # find similarity between query and candidate \n        cand_hypernym = torch.transpose(cand_hypernymT,0,1) #d*1\n        simPosHyper = torch.matmul(proj,cand_hypernym).to(device) #k*d x d*1 = k*1\n        simPosHyper = torch.squeeze(simPosHyper,1) # k\n        simPos = output(simPosHyper) # 1\n        \n        # find similarity between query and negative samples\n        #neg_hypernyms = torch.transpose(neg_hypernymsT,1,2) # ns*d*1\n        simNegHypersT = torch.matmul(neg_hypernymsT,projT).to(device) # ns*1*d x d*k= ns*1*k\n        simNegHypers = torch.transpose(simNegHypersT,1,2) # ns*k*1\n        simNegHypers = torch.squeeze(simNegHypers,2) # ns*k\n        simNegs = output(simNegHypers) # ns*1\n        simNegs = torch.squeeze(simNegs,1) # ns\n        \n        return simPos,simNegs\n    \n                \n        \n        \n","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:50:38.105498Z","iopub.execute_input":"2023-05-03T10:50:38.106270Z","iopub.status.idle":"2023-05-03T10:50:38.127839Z","shell.execute_reply.started":"2023-05-03T10:50:38.106216Z","shell.execute_reply":"2023-05-03T10:50:38.126642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# shuffled_vocab = copy.deepcopy(vocab)\n\ndef find_negative_samples(x):\n    answer = []\n    while len(answer)<neg_sample_count:\n        hm = random.choice(vocab)\n        if hm in hyponym_hypernyms[x] and hm not in vocab:\n            continue\n        else:\n            answer.append(word2index[hm])\n    \n    return answer","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:50:42.130942Z","iopub.execute_input":"2023-05-03T10:50:42.131491Z","iopub.status.idle":"2023-05-03T10:50:42.139667Z","shell.execute_reply.started":"2023-05-03T10:50:42.131446Z","shell.execute_reply":"2023-05-03T10:50:42.138656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_size = dim\nmodel = HHD(vocab_size,embedding_size)\nmodel.to(device)\n# model.to(device)   \n\ncriterion = nn.BCEWithLogitsLoss(weight=None, reduction=\"sum\")\noptimizer = optim.Adam(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:50:45.399513Z","iopub.execute_input":"2023-05-03T10:50:45.400259Z","iopub.status.idle":"2023-05-03T10:50:45.632671Z","shell.execute_reply.started":"2023-05-03T10:50:45.400219Z","shell.execute_reply":"2023-05-03T10:50:45.631625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,data,gold):\n    data_size = len(data)\n    queries = []\n    hypernyms = []\n    neg_samples = []\n    running_loss = []\n    rows = 0\n\n\n    for i, query in tqdm(enumerate(data)):\n        for j, hypernym in enumerate(gold[i]):\n            try:\n                q = word2index[query]\n                h = word2index[hypernym]\n            except:\n    #             print(query,hypernym)\n                continue\n\n            # add query to list\n            queries.append(q) #255 - batch size\n            # add hypermym to list\n            hypernyms.append(h) #255\n            # add negative samples to list\n            neg_samples.append(find_negative_samples(query)) # 255*5\n\n            rows += 1\n            if rows % batch_size == 0:\n\n                # make tensor from query list\n                queries_t = torch.tensor(queries, dtype=torch.long).to(device) #255\n                \n                # make tensor from hypernym list\n                hypernyms_t = torch.tensor(hypernyms, dtype=torch.long).to(device) #255\n                # make tensor form negative sampleS list\n                neg_samples_t = torch.tensor(neg_samples, dtype=torch.long).to(device) #255*5\n\n\n                # pass to model\n                optimizer.zero_grad()\n                simPos,simNegs = model(queries_t, hypernyms_t, neg_samples_t) #255*1 , 255*5\n\n    #             output = torch.cat((simPos,simNegs),1) #255*6\n    #             print(\"256*\")\n\n                y_pos = torch.ones((simPos.shape[0],1)).to(device) #255*1\n                y_neg = torch.zeros((simNegs.shape[0],neg_sample_count)).to(device) #255*5\n    #             target = torch.cat((y_pos,y_neg),1) #255*6\n\n                # calculate positive and negative loss\n                pos_loss = criterion(simPos, y_pos)\n                neg_loss = criterion(simNegs, y_neg)\n                loss = neg_loss + pos_loss\n\n                # back propogate the loss\n                loss.backward()\n                optimizer.step()\n                running_loss.append(loss.item())\n                # clear the lists\n\n                del queries_t\n                del hypernyms_t\n                del neg_samples_t\n\n                queries.clear()\n                hypernyms.clear()\n                neg_samples.clear()\n\n    epoch_loss = np.mean(running_loss)\n    print(\"Training epoch_loss is\", epoch_loss)\n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:50:48.279531Z","iopub.execute_input":"2023-05-03T10:50:48.280244Z","iopub.status.idle":"2023-05-03T10:50:48.291480Z","shell.execute_reply.started":"2023-05-03T10:50:48.280205Z","shell.execute_reply":"2023-05-03T10:50:48.290200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    train(model,data,gold)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:51:15.162379Z","iopub.execute_input":"2023-05-03T10:51:15.163076Z","iopub.status.idle":"2023-05-03T10:51:20.150455Z","shell.execute_reply.started":"2023-05-03T10:51:15.163036Z","shell.execute_reply":"2023-05-03T10:51:20.149363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model,data,gold):\n    \n    model.eval()\n    \n    data_size = len(data)\n    queries = []\n    hypernyms = []\n    neg_samples = []\n    running_loss = []\n    rows = 0\n\n\n    for i, query in tqdm(enumerate(data)):\n        for j, hypernym in enumerate(gold[i]):\n            try:\n                q = word2index[query]\n                h = word2index[hypernym]\n            except:\n    #             print(query,hypernym)\n                continue\n\n            # add query to list\n            queries.append(q) #255 - batch size\n            # add hypermym to list\n            hypernyms.append(h) #255\n            # add negative samples to list\n            neg_samples.append(find_negative_samples(query)) # 255*5\n\n            rows += 1\n            if rows % batch_size == 0:\n\n                # make tensor from query list\n                queries_t = torch.tensor(queries, dtype=torch.long).to(device) #255\n                \n                # make tensor from hypernym list\n                hypernyms_t = torch.tensor(hypernyms, dtype=torch.long).to(device) #255\n                # make tensor form negative sampleS list\n                neg_samples_t = torch.tensor(neg_samples, dtype=torch.long).to(device) #255*5\n\n\n                # pass to model\n#                 optimizer.zero_grad()\n                simPos,simNegs = model(queries_t, hypernyms_t, neg_samples_t) #255*1 , 255*5\n\n    #             output = torch.cat((simPos,simNegs),1) #255*6\n    #             print(\"256*\")\n\n                y_pos = torch.ones((simPos.shape[0],1)).to(device) #255*1\n                y_neg = torch.zeros((simNegs.shape[0],neg_sample_count)).to(device) #255*5\n    #             target = torch.cat((y_pos,y_neg),1) #255*6\n\n                # calculate positive and negative loss\n                pos_loss = criterion(simPos, y_pos)\n                neg_loss = criterion(simNegs, y_neg)\n                loss = neg_loss + pos_loss\n\n                # back propogate the loss\n#                 loss.backward()\n#                 optimizer.step()\n                running_loss.append(loss.item())\n                # clear the lists\n\n                del queries_t\n                del hypernyms_t\n                del neg_samples_t\n\n                queries.clear()\n                hypernyms.clear()\n                neg_samples.clear()\n\n    epoch_loss = np.mean(running_loss)\n    print(\"Training epoch_loss is\", epoch_loss)\n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:51:23.314067Z","iopub.execute_input":"2023-05-03T10:51:23.314444Z","iopub.status.idle":"2023-05-03T10:51:23.327195Z","shell.execute_reply.started":"2023-05-03T10:51:23.314410Z","shell.execute_reply":"2023-05-03T10:51:23.326001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model,data,gold)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:51:24.116279Z","iopub.execute_input":"2023-05-03T10:51:24.116698Z","iopub.status.idle":"2023-05-03T10:51:24.261344Z","shell.execute_reply.started":"2023-05-03T10:51:24.116659Z","shell.execute_reply":"2023-05-03T10:51:24.260299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(query):\n    data_size = len(data)\n    queries = []\n    hypernyms = []\n    neg_samples = []\n    running_loss = []\n    rows = 0\n    try:\n        q = torch.tensor([word2index[query]]).to(device)\n    except:\n        return \"word not found in vocab\"\n    closest_hypernyms = [] #[[similarity,word]]\n#     for i,cand_hypernym in tqdm(enumerate(vocab[:-2])):\n#         if query == cand_hypernym:\n#             continue\n        \n#         try:\n#             h = torch.tensor([word2index[cand_hypernym]])\n#         except:\n#             continue\n        \n#         s = model.similarity(q,h)\n        \n#         closest_hypernyms.append([s,cand_hypernym])\n    \n    h = torch.tensor(list(range(1,vocab_size))).to(device)\n    s = model.similarity(q,h,h.shape[0]) #bs*1\n#     to do - append similarities for all words\n    for i in range(1,vocab_size):\n        closest_hypernyms.append([float(s[i-1]),vocab[i]])\n    closest_hypernyms.sort(reverse=True)\n    answer = []\n    \n    l = 100\n    if l>len(closest_hypernyms):\n        l = len(closest_hypernyms)\n    \n    for i in range(l):\n        answer.append(closest_hypernyms[i][1])\n        \n    return answer","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:51:30.687532Z","iopub.execute_input":"2023-05-03T10:51:30.688246Z","iopub.status.idle":"2023-05-03T10:51:30.697503Z","shell.execute_reply.started":"2023-05-03T10:51:30.688208Z","shell.execute_reply":"2023-05-03T10:51:30.696459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(\"tropical_storm\")","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:51:32.897625Z","iopub.execute_input":"2023-05-03T10:51:32.897993Z","iopub.status.idle":"2023-05-03T10:51:32.905200Z","shell.execute_reply.started":"2023-05-03T10:51:32.897959Z","shell.execute_reply":"2023-05-03T10:51:32.904073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/HH_Projection_model_2B.pt')","metadata":{"execution":{"iopub.status.busy":"2023-05-03T10:53:32.042503Z","iopub.execute_input":"2023-05-03T10:53:32.043218Z","iopub.status.idle":"2023-05-03T10:53:32.297314Z","shell.execute_reply.started":"2023-05-03T10:53:32.043178Z","shell.execute_reply":"2023-05-03T10:53:32.296141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(model,data,gold)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model,data,gold)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    train(model,data,gold)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}